import streamlit as st
import google.generativeai as genai
import os
import random
from datetime import date

# 1. Page Configuration
st.set_page_config(page_title="KU SRC AI - ‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ", page_icon="ü¶ñ", layout="wide")

# 2. Premium CSS (Glassmorphism + KU Theme)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Kanit:wght@300;400;600&display=swap');
    * { font-family: 'Kanit', sans-serif; }
    .stApp { background: radial-gradient(circle at top left, #f0fdf4 0%, #ffffff 100%); }
    
    /* Sidebar */
    [data-testid="stSidebar"] { background-color: #004d43 !important; }
    [data-testid="stSidebar"] * { color: #ffffff !important; }

    /* Glass Chat Bubbles */
    .stChatMessage {
        background: rgba(255, 255, 255, 0.7) !important;
        backdrop-filter: blur(12px);
        border: 1px solid rgba(255, 255, 255, 0.4);
        border-radius: 20px !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05) !important;
    }

    /* Quick Action Buttons */
    div.stButton > button {
        border-radius: 20px !important;
        border: 1px solid #00594C !important;
        transition: all 0.3s ease;
        width: 100%;
    }
    div.stButton > button:hover {
        background-color: #00594C !important;
        color: white !important;
        transform: translateY(-2px);
    }

    /* Header Styling */
    .main-title {
        font-size: 38px; font-weight: 800;
        background: linear-gradient(90deg, #00594C, #2D6A4F);
        -webkit-background-clip: text; -webkit-text-fill-color: transparent;
    }
</style>
""", unsafe_allow_html=True)

# 3. Model Logic (Auto-Detect)
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡∏•‡∏∑‡∏°‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GEMINI_API_KEY ‡πÉ‡∏ô Secrets ‡∏Ñ‡∏£‡∏±‡∏ö‡∏Æ‡∏≠‡∏ô")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_ai_model():
    try:
        # ‡πÉ‡∏ä‡πâ‡∏£‡∏∏‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        return genai.GenerativeModel('gemini-1.5-flash')
    except:
        return None

model = load_ai_model()

# 4. Sidebar Content (Function 3 & 4)
with st.sidebar:
    st.markdown("<h1 style='text-align:center;'>ü¶ñ</h1>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align:center;'>‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ Digital Assistant</h3>", unsafe_allow_html=True)
    
    # Event Countdown (Function 3)
    exam_date = date(2026, 3, 2) # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡∏±‡∏ô‡∏™‡∏≠‡∏ö
    days_left = (exam_date - date.today()).days
    st.info(f"üìÖ ‡∏≠‡∏µ‡∏Å {days_left} ‡∏ß‡∏±‡∏ô‡∏à‡∏∞‡∏ñ‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏ô‡∏≠‡∏•!")
    
    if st.button("‚ú® ‡∏•‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    # Multi-modal Input (Function 1)
    st.markdown("üì∑ **‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡πÉ‡∏´‡πâ‡∏û‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏π‡πÑ‡∏î‡πâ‡∏ô‡∏∞**")
    uploaded_file = st.file_uploader("‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£", type=['png', 'jpg', 'jpeg'])

# 5. Main UI
st.markdown("<h1 class='main-title'>ü¶ñ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ AI (KU SRC)</h1>", unsafe_allow_html=True)

# Quick Reply & Utility (Function 3 & 5)
col1, col2, col3, col4 = st.columns(4)
btn_prompt = None
with col1:
    if st.button("üìç ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"): btn_prompt = "‡∏Ç‡∏≠‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á"
with col2:
    if st.button("üé≤ ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏°‡∏ô‡∏π‡∏≠‡∏≤‡∏´‡∏≤‡∏£"):
        menus = ["‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà‡πÇ‡∏£‡∏á 1", "‡∏Å‡πã‡∏ß‡∏¢‡πÄ‡∏ï‡∏µ‡πã‡∏¢‡∏ß‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏≠", "‡∏™‡πÄ‡∏ï‡πá‡∏Å‡πÄ‡∏î‡πá‡∏Å‡πÅ‡∏ô‡∏ß", "‡∏™‡πâ‡∏°‡∏ï‡∏≥‡∏õ‡πâ‡∏≤‡πÅ‡∏î‡∏á"]
        choice = random.choice(menus)
        btn_prompt = f"‡∏û‡∏µ‡πà‡∏™‡∏∏‡πà‡∏°‡πÑ‡∏î‡πâ '{choice}' ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ô‡πâ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏£‡πâ‡∏≤‡∏ô‡∏ô‡∏µ‡πâ‡πÇ‡∏≠‡πÄ‡∏Ñ‡πÑ‡∏´‡∏°?"
with col3:
    if st.button("üìö ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠"): btn_prompt = "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÜ ‡πÉ‡∏ô‡∏°‡∏≠‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏û‡∏µ‡πà"
with col4:
    if st.button("üöå ‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•‡∏™‡∏≤‡∏¢‡πÑ‡∏´‡∏ô?"): btn_prompt = "‡∏à‡∏∞‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏°‡∏≠ ‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•‡∏™‡∏≤‡∏¢‡πÑ‡∏´‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö"

# 6. Chat Logic
if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"], avatar="üßë‚Äçüéì" if m["role"] == "user" else "ü¶ñ"):
        st.markdown(m["content"])

# Input Handling
chat_input = st.chat_input("‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢...")
prompt = chat_input if chat_input else btn_prompt

if prompt:
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡πà‡∏á User
    with st.chat_message("user", avatar="üßë‚Äçüéì"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ‡∏ù‡∏±‡πà‡∏á AI ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö
    with st.chat_message("assistant", avatar="ü¶ñ"):
        status = st.empty()
        status.markdown("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î‡πÅ‡∏õ‡πä‡∏ö‡∏ô‡∏∂‡∏á‡∏ô‡∏∞‡∏ô‡πâ‡∏≠‡∏á...")

        # ‡∏£‡∏∞‡∏ö‡∏ö Knowledge Base ‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (Function 5)
        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡πÉ‡∏à‡∏î‡∏µ‡πÅ‡∏´‡πà‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ "
            "‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏™‡∏ô‡∏¥‡∏ó‡∏™‡∏ô‡∏° ‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏û‡∏µ‡πà ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤‡∏ô‡πâ‡∏≠‡∏á "
            "‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô 'Inside' ‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡πâ‡∏≤‡∏ô‡πÑ‡∏´‡∏ô‡∏£‡∏≠‡∏ô‡∏≤‡∏ô ‡∏ï‡∏∂‡∏Å‡πÑ‡∏´‡∏ô‡πÅ‡∏≠‡∏£‡πå‡∏´‡∏ô‡∏≤‡∏ß "
            "‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ ‡πÉ‡∏´‡πâ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏ô‡∏±‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ô‡∏¥‡∏™‡∏¥‡∏ï"
        )
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Model
        content_to_send = [f"{instruction}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"]
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ (Function 1)
        if uploaded_file:
            import PIL.Image
            img = PIL.Image.open(uploaded_file)
            content_to_send.append(img)
            content_to_send.append("‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏∞‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà ‡∏°‡∏Å. ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö")

        try:
            response = model.generate_content(content_to_send)
            status.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            status.empty()
            st.error(f"‡∏û‡∏µ‡πà‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢: {e}")
