import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="KU Sriracha AI Bot", page_icon="ü¶ñ", layout="wide")

# --- UI Customization (KU Green Premium Theme) ---
st.markdown("""
<style>
    /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ö‡∏ö‡πÑ‡∏•‡πà‡πÄ‡∏â‡∏î‡∏™‡∏µ‡∏ô‡∏ß‡∏•‡∏ï‡∏≤ */
    .stApp {
        background: linear-gradient(135deg, #f5fcf8 0%, #ffffff 100%);
    }

    /*Sidebar - ‡∏™‡πÑ‡∏ï‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏°‡πÅ‡∏ö‡∏ö‡∏û‡∏£‡∏µ‡πÄ‡∏°‡∏µ‡∏¢‡∏° */
    [data-testid="stSidebar"] {
        background-color: #004d43 !important;
        box-shadow: 2px 0px 10px rgba(0,0,0,0.1);
    }
    [data-testid="stSidebar"] * { color: #ffffff !important; }
    
    /* ‡∏õ‡∏∏‡πà‡∏°‡πÉ‡∏ô Sidebar */
    .stSidebar [button] {
        border-radius: 10px;
        border: 1px solid rgba(255,255,255,0.2);
        background-color: rgba(255,255,255,0.1);
    }

    /* ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏•‡∏±‡∏Å */
    h1 {
        color: #00594C !important;
        font-family: 'Kanit', sans-serif;
        font-weight: 700;
        letter-spacing: -1px;
    }

    /* ‡∏Å‡∏≤‡∏£‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó (Glassmorphism) */
    .stChatMessage {
        border-radius: 20px !important;
        margin-bottom: 1rem !important;
        padding: 1.5rem !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.03) !important;
    }
    
    /* ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (User) - ‡∏ä‡∏¥‡∏î‡∏Ç‡∏ß‡∏≤ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏≠‡πà‡∏≠‡∏ô */
    div[data-testid="stChatMessage"]:has(span:contains("üßë‚Äçüéì")) {
        background-color: #e8f5e9 !important;
        border: 1px solid #c8e6c9 !important;
        margin-left: 15% !important;
    }

    /* ‡∏ö‡∏≠‡∏ó (Assistant) - ‡∏ä‡∏¥‡∏î‡∏ã‡πâ‡∏≤‡∏¢ ‡∏Ç‡∏≤‡∏ß‡∏™‡∏∞‡∏≠‡∏≤‡∏î */
    div[data-testid="stChatMessage"]:has(span:contains("ü¶ñ")) {
        background-color: #ffffff !important;
        border: 1px solid #f0f0f0 !important;
        margin-right: 15% !important;
    }

    /* ‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏≤‡∏á‡∏•‡∏±‡∏î (Quick Reply) - ‡∏ó‡∏£‡∏á‡∏°‡∏ô‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏° */
    div.stButton > button {
        border-radius: 30px !important;
        border: 1px solid #00594C !important;
        color: #00594C !important;
        background-color: #ffffff !important;
        font-weight: 500 !important;
        padding: 0.5rem 1rem !important;
        transition: all 0.3s ease !important;
    }
    div.stButton > button:hover {
        background-color: #00594C !important;
        color: #ffffff !important;
        transform: scale(1.05);
    }

    /* ‡∏à‡∏∏‡∏î Loading ‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏™‡∏µ‡∏™‡∏±‡∏ô */
    .loading-dots {
        font-size: 30px;
        color: #00594C;
        letter-spacing: 5px;
    }
    .loading-dots:after {
        content: '.';
        animation: dots 1.5s infinite;
    }
    @keyframes dots {
        0%, 20% { content: '.'; }
        40% { content: '..'; }
        60% { content: '...'; }
        80%, 100% { content: ''; }
    }
</style>
""", unsafe_allow_html=True)

# --- Logic & API Setup ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if "flash" in m.name.lower():
                    return genai.GenerativeModel(model_name=m.name)
        return genai.GenerativeModel(model_name='gemini-1.5-flash')
    except: return None

model = load_model()

# --- Sidebar ---
with st.sidebar:
    st.markdown("<h2 style='text-align: center;'>KU SRC AI</h2>", unsafe_allow_html=True)
    st.markdown("---")
    if st.button("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà"):
        st.session_state.messages = []
        st.rerun()
    st.markdown("<br><br>", unsafe_allow_html=True)
    st.caption("‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô 1.5 - ‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡πÑ‡∏ß‡∏û‡∏¥‡πÄ‡∏®‡∏©")

# --- Main Page ---
st.title("ü¶ñ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ AI")
st.markdown("<p style='color: #666;'>‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡πâ‡∏≠‡∏á‡πÜ ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö!</p>", unsafe_allow_html=True)

# Quick Reply Buttons
st.markdown("---")
btn_prompt = None
c1, c2, c3, c4 = st.columns(4)
with c1:
    if st.button("üè¢ ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"): btn_prompt = "‡∏Ç‡∏≠‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"
with c2:
    if st.button("üçú ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏≠‡∏á‡∏Å‡∏¥‡∏ô"): btn_prompt = "‡πÅ‡∏ñ‡∏ß‡∏°‡∏≠‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡∏ö‡πâ‡∏≤‡∏á ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
with c3:
    if st.button("üìë ‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"): btn_prompt = "‡∏≠‡∏¢‡∏≤‡∏Å‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô"
with c4:
    if st.button("üöê ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•"): btn_prompt = "‡∏Ç‡∏≠‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏î‡∏¥‡∏ô‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•‡∏Ñ‡∏£‡∏±‡∏ö"

# Message History
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# Chat Input Logic
chat_input = st.chat_input("‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ...")
prompt = chat_input if chat_input else btn_prompt

if prompt:
    with st.chat_message("user", avatar="üßë‚Äçüéì"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        status_placeholder = st.empty()
        status_placeholder.markdown('<div class="loading-dots"></div>', unsafe_allow_html=True)
        
        # Load Knowledge Base
        kb = ""
        if os.path.exists("ku_data.txt"):
            with open("ku_data.txt", "r", encoding="utf-8") as f:
                kb = f.read()

        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' AI ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡πÅ‡∏´‡πà‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ (KU SRC) "
            "‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤ '‡∏û‡∏µ‡πà' ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤ '‡∏ô‡πâ‡∏≠‡∏á' "
            "‡∏à‡∏á‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏´‡∏≤‡∏Å‡πÄ‡∏Ç‡∏≤‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Ç‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏™‡∏°‡∏≠ "
            "‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏£‡∏ß‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£"
        )
        
        history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-10:]])
        full_p = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {kb}\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢:\n{history}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
        
        try:
            response = model.generate_content(full_p)
            status_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            status_placeholder.empty()
            st.error(f"‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏ó‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö‡∏ô‡πâ‡∏≠‡∏á ‡∏û‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢: {e}")
