import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ - KU Sriracha Bot", page_icon="üêØ", layout="wide")

# --- CSS ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á UI ‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô ---
st.markdown("""
<style>
    .stApp { background-color: #FFFFFF; color: black; }
    [data-testid="stSidebar"] { background-color: #00594C !important; color: white; }
    .stSidebar [data-testid="stMarkdownContainer"] p { color: white !important; font-weight: bold; }
    h1, h2, h3 { color: #00594C !important; }
    
    /* ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà */
    .map-button {
        display: inline-block;
        padding: 8px 16px;
        background-color: #00594C;
        color: white !important;
        text-decoration: none;
        border-radius: 5px;
        font-weight: bold;
        margin-top: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ API ‡πÅ‡∏•‡∏∞ Model ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GEMINI_API_KEY ‡πÉ‡∏ô Streamlit Secrets")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        # ‡πÉ‡∏ä‡πâ System Instruction ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏°‡∏ö‡∏∏‡∏Ñ‡∏•‡∏¥‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô
        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' AI ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ ‡∏°‡∏Å. (KU SRC) "
            "‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏ô‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢ "
            "1. ‡∏´‡∏≤‡∏Å‡∏£‡∏∏‡πà‡∏ô‡∏ô‡πâ‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏° ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå PDF ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ "
            "2. ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡∏´‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà "
            "3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏•‡∏Ç‡∏û‡∏¥‡∏Å‡∏±‡∏î GPS (Lat, Long) ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏ó‡∏ô "
            "4. ‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤ '‡∏û‡∏µ‡πà' ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤ '‡∏ô‡πâ‡∏≠‡∏á'"
        )
        return genai.GenerativeModel(model_name="gemini-1.5-flash", system_instruction=instruction)
    except:
        return None

model = load_model()

# --- ‡∏™‡πà‡∏ß‡∏ô Sidebar: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ---
with st.sidebar:
    st.image("https://www.src.ku.ac.th/th/images/logo/KU_Sriracha_Logo.png", width=150)
    st.markdown("### üìç ‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.")
    # ‡∏ù‡∏±‡∏á Google Maps ‡∏Ç‡∏≠‡∏á ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.
    map_html = '<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m13!1d3882.388836268392!2d100.91745677579698!3d13.113264611202888!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x3102b70f0687779f%3A0xc9b039868725d78a!2z4Lih4Lir4Liy4Lin4Li04LiX4Lii4Liy4Lis4Liy4LiZ4LmA4LiB4Lip4Lij4Liy4LiB4Liy4LijIOC4p-C4tOC4l-C4ouC4sOC4quC4o-C4teC5gOC4guC4leC4qOC4o-C4teC4iuC4siAoc3JpcmFjaGEp!5e0!3m2!1sth!2sth!4v1708600000000!5m2!1sth!2sth" width="100%" height="300" style="border:0; border-radius:10px;" allowfullscreen="" loading="lazy"></iframe>'
    st.components.v1.html(map_html, height=320)
    st.info("üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö: ‡∏ô‡πâ‡∏≠‡∏á‡πÜ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≤‡∏°‡∏ó‡∏≤‡∏á‡πÑ‡∏õ‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≠‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ö KU3 ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞!")

# --- ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å ---
st.title("üêØ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏π‡πà‡∏Ñ‡∏¥‡∏î ‡∏ô‡∏¥‡∏™‡∏¥‡∏ï ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.")

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ku_data.txt
if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢
for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "üêØ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# ‡∏™‡πà‡∏ß‡∏ô‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ñ‡∏≤‡∏°‡∏û‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô '‡∏Ç‡∏≠‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£ 10 ‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡πÑ‡∏´‡∏ô'"):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="üêØ"):
        placeholder = st.empty()
        placeholder.markdown("*(‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ô‡∏∞...)*")
        
        # ‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ 5 ‡∏£‡∏≠‡∏ö‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token
        history = st.session_state.messages[-5:]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÅ‡∏ö‡∏ö RAG
        full_context = f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:\n{knowledge_base}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
        
        try:
            # ‡πÉ‡∏ä‡πâ chat session ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
            chat = model.start_chat(history=[
                {"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                for m in st.session_state.messages[:-1]
            ])
            
            response = chat.send_message(full_context, stream=True)
            full_response = ""
            for chunk in response:
                full_response += chunk.text
                placeholder.markdown(full_response + "‚ñå")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()
            
        except Exception as e:
            placeholder.empty()
            st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
