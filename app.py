import streamlit as st
import google.generativeai as genai
import os
import base64

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ---
st.set_page_config(page_title="AI KUSRC", page_icon="üêØ", layout="wide")

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ç‡∏ô‡∏≤‡∏î ---
def get_image_base64(path):
    with open(path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

# --- 3. CSS ‡∏à‡∏±‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏£‡∏ü‡πÄ‡∏ü‡∏≠‡πÄ‡∏£‡∏ô‡∏ã‡πå‡πÄ‡∏õ‡πä‡∏∞‡πÜ ---
st.markdown("""
<style>
    .stApp { background-color: #FFFFFF; color: black; }
    
    /* Sidebar ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÑ‡∏•‡πà‡πÄ‡∏â‡∏î (Gradient) ‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ */
    [data-testid="stSidebar"] { 
        background: linear-gradient(180deg, #00594C 0%, #003d34 100%) !important;
        padding-top: 0px;
    }

    /* ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏•‡πÇ‡∏Å‡πâ Header ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î */
    .header-container {
        text-align: center;
        padding: 20px 10px;
        background: transparent;
    }
    .header-logo {
        width: 100%;
        max-width: 250px;
        height: auto;
    }

    /* ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Dashboard */
    .sidebar-title {
        color: white !important;
        font-size: 1.2rem;
        font-weight: bold;
        margin: 15px 0px;
        display: flex;
        align-items: center;
        gap: 10px;
    }

    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏° (White Card) */
    .form-container {
        background-color: white;
        border-radius: 10px;
        padding: 10px;
        margin-top: 5px;
    }
    
    /* ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß */
    .form-item {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 10px;
        border-bottom: 1px solid #eee;
        color: black !important;
    }
    .form-item:last-child { border-bottom: none; }
    
    .form-text {
        font-size: 0.9rem;
        font-weight: 500;
        color: #333 !important;
        line-height: 1.2;
    }

    /* ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß */
    .download-btn {
        background-color: #00594C;
        color: white !important;
        padding: 5px 12px;
        border-radius: 5px;
        text-decoration: none;
        font-size: 0.8rem;
        font-weight: bold;
        white-space: nowrap;
    }

    /* ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Expander ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡πÅ‡∏•‡∏∞‡∏î‡∏π‡∏Ñ‡∏•‡∏µ‡∏ô */
    .st-emotion-cache-p5mtransition {
        background-color: white !important;
        border-radius: 10px !important;
    }
    .st-emotion-cache-p5mtransition p {
        color: black !important;
        font-weight: bold !important;
    }

    /* Chat UI */
    h2 { color: #00594C !important; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- 4. ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ API ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        selected = next((m for m in available_models if "1.5-flash" in m), available_models[0])
        return genai.GenerativeModel(model_name=selected)
    except: return None

model = load_model()

# --- 5. ‡∏™‡πà‡∏ß‡∏ô Sidebar: ‡πÅ‡∏î‡∏ä‡∏ö‡∏≠‡∏£‡πå‡∏î‡πÅ‡∏ö‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ ---
with st.sidebar:
    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏•‡πÇ‡∏Å‡πâ‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß‡∏ö‡∏ô‡∏™‡∏∏‡∏î
    if os.path.exists("logo_ku.png"):
        img_base64 = get_image_base64("logo_ku.png")
        st.markdown(f"""
            <div class="header-container">
                <img src="data:image/png;base64,{img_base64}" class="header-logo">
            </div>
        """, unsafe_allow_html=True)
    
    st.markdown('<div class="sidebar-title">üéì ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ Student Dashboard</div>', unsafe_allow_html=True)

    # ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°
    with st.expander("üìÑ ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πà‡∏ß‡∏ô (‡∏Ñ‡∏•‡∏¥‡∏Å)", expanded=True):
        st.markdown(f"""
            <div class="form-container">
                <div class="form-item">
                    <div class="form-text">üìù ‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô<br>(Registrar-2)</div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2024/11/Request-for-Registration.pdf" target="_blank" class="download-btn">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-item">
                    <div class="form-text">üí∞ ‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ<br>(Registrar-1)</div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2023/11/General-Request.pdf" target="_blank" class="download-btn">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-item">
                    <div class="form-text">üìÇ ‡πÉ‡∏ö‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤<br>(Registrar-10)</div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2023/11/Request-for-Leave-of-Absence-Request.pdf" target="_blank" class="download-btn">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-item">
                    <div class="form-text">üìÑ Add-Drop (KU3)<br>‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå</div>
                    <a href="https://reg2.src.ku.ac.th/download.html" target="_blank" class="download-btn">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
            </div>
        """, unsafe_allow_html=True)

    st.markdown("<br><br>", unsafe_allow_html=True)
    st.caption("üíö ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏™‡∏¥‡∏ï ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.")

# --- 6. ‡∏™‡πà‡∏ß‡∏ô Chat ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

st.markdown("## üêØ AI KUSRC")

for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "üêØ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ñ‡∏≤‡∏°‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢..."):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="üêØ"):
        placeholder = st.empty()
        placeholder.markdown("*(‡∏û‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ...)*")
        
        history = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                   for m in st.session_state.messages[-6:-1]]
        
        try:
            chat_session = model.start_chat(history=history)
            full_context = f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà ‡∏°‡∏Å.‡∏®‡∏£‡∏ä. ‡∏ï‡∏≠‡∏ö‡∏ô‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n{knowledge_base}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
            
            response = chat_session.send_message(full_context, stream=True)
            full_response = ""
            for chunk in response:
                full_response += chunk.text
                placeholder.markdown(full_response + "‚ñå")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")
