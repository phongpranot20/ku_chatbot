import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="KU Sriracha Bot", page_icon="üê¢", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #FFFFFF !important; color: black !important; }
    [data-testid="stSidebar"] { background-color: #f2f9f6 !important; }
    h1, h2, h3, p, span, div { color: #00594C; }
    [data-testid="stChatMessage"] { background-color: #f0f2f6; border-radius: 10px; }
    .stMarkdown p { color: #333333 !important; }
</style>
""", unsafe_allow_html=True)

api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Settings > Secrets")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if "1.5" in m.name:
                    return genai.GenerativeModel(model_name=m.name, tools=[{"google_search": {}}])
    except:
        pass

    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if "1.5" in m.name:
                    return genai.GenerativeModel(model_name=m.name, tools=[{"google_search_retrieval": {}}])
    except:
        pass

    for m in genai.list_models():
        if 'generateContent' in m.supported_generation_methods:
            return genai.GenerativeModel(m.name)
    return None

model = load_model()

if not model:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ")
    st.stop()

st.title("AI TEST")

if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"):
        st.markdown(message["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á placeholder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î
        status_placeholder = st.empty()
        status_placeholder.markdown("...") 
        
        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' AI ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏Ç‡∏≠‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ (KU SRC) "
            "‡∏†‡∏≤‡∏£‡∏Å‡∏¥‡∏à: ‡∏à‡∏á‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ "
            "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏∂‡∏Å ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏°‡∏≠ "
            "‡πÅ‡∏•‡∏∞‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏≤‡∏à‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå‡∏°‡∏≤‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢"
        )
        
        history_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-10:]])
        full_prompt = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {knowledge_base}\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢:\n{history_text}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {prompt}"
        
        try:
            response = model.generate_content(full_prompt)
            # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á
            status_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            try:
                base_model = genai.GenerativeModel(model.model_name)
                response = base_model.generate_content(full_prompt)
                status_placeholder.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e2:
                status_placeholder.empty() # ‡∏•‡∏ö‡∏à‡∏∏‡∏î‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î Error
                st.error(f"‚ùå ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e2}")
