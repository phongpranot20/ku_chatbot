import streamlit as st
import google.generativeai as genai
import os
import base64

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ---
st.set_page_config(page_title="AI ASSISTANT", page_icon="ü¶ñ", layout="wide")

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÇ‡∏•‡πÇ‡∏Å‡πâ ---
def get_image_base64(path):
    with open(path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

# --- 3. CSS ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á (‡∏Ç‡∏¢‡∏±‡∏ö Header ‡∏ä‡∏¥‡∏î‡∏ö‡∏ô + ‡πÅ‡∏Å‡πâ‡∏™‡∏µ Expander) ---
st.markdown("""
<style>
    /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏´‡∏•‡∏±‡∏Å */
    .stApp { background-color: #FFFFFF; color: black; }
    
    /* Sidebar: ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏´‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏î */
    [data-testid="stSidebar"] { 
        background-color: #006861 !important; 
    }

    /* ‡∏Ç‡∏¢‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô Sidebar Content ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏´‡πâ‡∏ä‡∏¥‡∏î‡∏Ç‡∏≠‡∏ö‡∏ö‡∏ô */
    [data-testid="stSidebarContent"] {
        padding-top: 0rem !important;
    }

    /* ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Header: ‡πÇ‡∏•‡πÇ‡∏Å‡πâ‡∏ö‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢‡∏•‡πà‡∏≤‡∏á (‡∏Ç‡∏¢‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡∏ä‡∏¥‡∏î‡∏ö‡∏ô) */
    .custom-header {
        display: flex;
        flex-direction: column;
        align-items: center;
        text-align: center;
        padding: 10px 5px 20px 5px; /* ‡∏•‡∏î Padding ‡∏ö‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î */
        margin-top: -30px; /* ‡∏Ç‡∏¢‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏ä‡∏¥‡∏î‡∏Ç‡∏≠‡∏ö */
        border-bottom: 2px solid rgba(255,255,255,0.2);
    }
    .header-logo-img {
        width: 100px;
        height: auto;
        margin-bottom: 10px;
    }
    .header-text {
        color: white !important;
        font-family: 'Tahoma', sans-serif;
    }
    .univ-name { 
        font-size: 24px;
        font-weight: bold;
        line-height: 1.2;
    }

    /* ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Dashboard */
    .sidebar-title {
        color: #FFFFFF !important;
        font-size: 1.1rem;
        font-weight: bold;
        margin: 15px 0px 10px 0px;
        text-align: center;
    }

    /* --- ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Expander ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤ (‡πÑ‡∏°‡πà‡∏Å‡∏•‡∏∑‡∏ô‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á) --- */
    .st-emotion-cache-p5mtransition, div[data-testid="stExpander"] {
        background-color: #FFFFFF !important;
        border-radius: 12px !important;
        border: none !important;
    }
    
    /* ‡∏™‡∏µ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Expander (‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ) */
    div[data-testid="stExpander"] p {
        color: #000000 !important;
        font-weight: bold !important;
    }

    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏Ç‡∏≤‡∏ß‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô */
    .white-card-content {
        background-color: #FFFFFF;
        padding: 5px;
    }
    
    .form-row {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 12px 10px;
        border-bottom: 1px solid #f0f0f0;
    }
    .form-row:last-child { border-bottom: none; }
    
    .form-label {
        color: #333333 !important;
        font-size: 13px;
        font-weight: 600;
        flex: 1;
    }

    /* ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡πÄ‡∏Ç‡πâ‡∏° */
    .btn-download {
        background-color: #006861;
        color: white !important;
        padding: 5px 12px;
        border-radius: 6px;
        text-decoration: none;
        font-size: 11px;
        font-weight: bold;
    }

    /* ‡∏´‡∏ô‡πâ‡∏≤ Chat */
    h2 { color: #006861 !important; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- 4. ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ API ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API KEY")
    st.stop()
genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        selected = next((m for m in available_models if "1.5-flash" in m), available_models[0])
        return genai.GenerativeModel(model_name=selected)
    except: return None
model = load_model()

# --- 5. ‡∏™‡πà‡∏ß‡∏ô Sidebar (Dashboard) ---
with st.sidebar:
    # 1. Custom Header (‡∏Ç‡∏¢‡∏±‡∏ö‡∏ä‡∏¥‡∏î‡∏ö‡∏ô‡∏™‡∏∏‡∏î)
    if os.path.exists("logo_ku.png"):
        img_data = get_image_base64("logo_ku.png")
        st.markdown(f"""
            <div class="custom-header">
                <img src="data:image/png;base64,{img_data}" class="header-logo-img">
                <div class="header-text">
                    <div class="univ-name">‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢<br>‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå</div>
                </div>
            </div>
        """, unsafe_allow_html=True)
    
    

    # 2. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πà‡∏ß‡∏ô (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏µ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏Å‡∏•‡∏∑‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á)
    with st.expander("üìÑ ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÜ ", expanded=True):
        st.markdown(f"""
            <div class="white-card-content">
                <div class="form-row">
                    <div class="form-label">‡πÉ‡∏ö‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô</div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2024/11/Request-for-Registration.pdf" target="_blank" class="btn-download">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-row">
                    <div class="form-label">‡πÉ‡∏ö‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ </div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2023/11/General-Request.pdf" target="_blank" class="btn-download">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-row">
                    <div class="form-label">‡πÉ‡∏ö‡∏•‡∏≤‡∏û‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ </div>
                    <a href="https://registrar.ku.ac.th/wp-content/uploads/2023/11/Request-for-Leave-of-Absence-Request.pdf" target="_blank" class="btn-download">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
                <div class="form-row">
                    <div class="form-label">‡πÉ‡∏ö Add-Drop </div>
                    <a href="https://reg2.src.ku.ac.th/download.html" target="_blank" class="btn-download">‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î</a>
                </div>
            </div>
        """, unsafe_allow_html=True)

    # ‡∏•‡∏ö‡∏™‡πà‡∏ß‡∏ô Caption ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡∏≠‡∏≠‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢

# --- 6. ‡∏™‡πà‡∏ß‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Chat ‡∏´‡∏•‡∏±‡∏Å ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÇ‡∏´‡∏•‡∏î Knowledge Base
if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

st.markdown("## ü¶ñ AI ASSISTANT")

for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ñ‡∏≤‡∏°‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢..."):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        placeholder = st.empty()
        placeholder.markdown("*(‡∏û‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ...)*")
        
        history = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                   for m in st.session_state.messages[-6:-1]]
        
        try:
            chat_session = model.start_chat(history=history)
            full_context = f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà ‡∏°‡∏Å.‡∏®‡∏£‡∏ä. ‡∏ï‡∏≠‡∏ö‡∏ô‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n{knowledge_base}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
            
            response = chat_session.send_message(full_context, stream=True)
            full_response = ""
            for chunk in response:
                full_response += chunk.text
                placeholder.markdown(full_response + "‚ñå")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")
