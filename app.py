import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="KU SRC AI - ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ", page_icon="ü¶ñ", layout="wide")

# --- CUSTOM CSS: ULTIMATE DESIGN WITH SIDEBAR STYLE ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Kanit:wght@300;400;600&display=swap');
    * { font-family: 'Kanit', sans-serif; }
    .stApp { background: radial-gradient(circle at top left, #f0fdf4 0%, #ffffff 100%); }
    
    /*Sidebar - ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏û‡∏£‡∏µ‡πÄ‡∏°‡∏µ‡∏¢‡∏°‡πÄ‡∏Ç‡πâ‡∏° */
    [data-testid="stSidebar"] {
        background-color: #004d43 !important;
        border-right: 1px solid rgba(255,255,255,0.1);
        color: white !important;
    }
    [data-testid="stSidebar"] * { color: white !important; }
    
    /* ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏ô Sidebar */
    .sidebar-title {
        font-size: 20px;
        font-weight: 600;
        text-align: center;
        margin-bottom: 20px;
    }

    /* ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á Chat Bubbles */
    .stChatMessage {
        background: rgba(255, 255, 255, 0.7) !important;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.4);
        border-radius: 20px !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05) !important;
        margin-bottom: 10px !important;
    }

    /* ‡∏à‡∏∏‡∏î Loading */
    .loading-container { display: flex; gap: 5px; padding: 10px; }
    .dot { width: 10px; height: 10px; background: #00594C; border-radius: 50%; animation: wave 1.3s linear infinite; }
    .dot:nth-child(2) { animation-delay: -1.1s; }
    .dot:nth-child(3) { animation-delay: -0.9s; }
    @keyframes wave { 0%, 60%, 100% { transform: translateY(0); } 30% { transform: translateY(-10px); } }
</style>
""", unsafe_allow_html=True)

# --- AI SETUP ---
api_key = st.secrets.get("GEMINI_API_KEY")
genai.configure(api_key=api_key)

@st.cache_resource
def load_ai():
    try:
        # ‡∏£‡∏∞‡∏ö‡∏ö‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏°‡πà‡∏û‡∏±‡∏á
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if "flash" in m.name.lower(): return genai.GenerativeModel(m.name)
        return genai.GenerativeModel('gemini-1.5-flash')
    except: return None

model = load_ai()

# --- SIDEBAR: CHAT HISTORY & INFO ---
with st.sidebar:
    st.markdown("<div class='sidebar-title'>ü¶ñ ‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ History</div>", unsafe_allow_html=True)
    
    # ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πà‡∏≠ (‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå)
    if "messages" in st.session_state and len(st.session_state.messages) > 0:
        st.markdown("üí¨ **‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î:**")
        # ‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å User 5 ‡∏≠‡∏±‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        user_msgs = [m["content"] for m in st.session_state.messages if m["role"] == "user"]
        for msg in user_msgs[-5:]:
            st.caption(f"‚Ä¢ {msg[:30]}..." if len(msg) > 30 else f"‚Ä¢ {msg}")
    else:
        st.caption("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢‡πÉ‡∏ô‡πÄ‡∏ã‡∏™‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ")

    st.markdown("---")
    
    # ‡∏õ‡∏∏‡πà‡∏°‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏ä‡∏ó‡πÅ‡∏ö‡∏ö‡∏™‡∏ß‡∏¢‡πÜ
    if st.button("‚ú® ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# --- MAIN CONTENT ---
st.title("ü¶ñ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ AI (KU SRC)")

if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ä‡∏ó‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å)
for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# ‡∏£‡∏±‡∏ö Input
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ..."):
    with st.chat_message("user", avatar="üßë‚Äçüéì"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        status = st.empty()
        status.markdown('<div class="loading-container"><div class="dot"></div><div class="dot"></div><div class="dot"></div></div>', unsafe_allow_html=True)
        
        # Load Knowledge Base
        kb = ""
        if os.path.exists("ku_data.txt"):
            with open("ku_data.txt", "r", encoding="utf-8") as f: kb = f.read()

        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏Ç‡∏≠‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ "
            "‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏û‡∏µ‡πà ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏°‡∏≠"
        )
        
        # ‡∏™‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 10 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏ó‡∏à‡∏≥‡πÑ‡∏î‡πâ (Memory)
        history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-10:]])
        full_p = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {kb}\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥: {history}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
        
        try:
            response = model.generate_content(full_p)
            status.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            # ‡∏™‡∏±‡πà‡∏á rerun ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ô Sidebar ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
            st.rerun()
        except Exception as e:
            status.empty()
            st.error(f"‡∏û‡∏µ‡πà‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢: {e}")
