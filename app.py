import streamlit as st
import google.generativeai as genai
import os

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ---
st.set_page_config(page_title="‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ - KU Sriracha Bot", page_icon="üêØ", layout="wide")

# --- 2. CSS ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠ (Force Black Text) ---
st.markdown("""
<style>
    .stApp { background-color: #FFFFFF; color: black; }
    
    /* Sidebar Layout */
    [data-testid="stSidebar"] { background-color: #00594C !important; }
    
    /* ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ Dashboard */
    .sidebar-header {
        color: white !important;
        font-size: 20px;
        font-weight: bold;
        margin-top: 10px;
        margin-bottom: 20px;
    }

    /* ‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏° */
    .white-card {
        background-color: #FFFFFF;
        border-radius: 12px;
        padding: 15px;
        margin-bottom: 15px;
        border: 1px solid #ddd;
    }

    /* ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏™‡∏µ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÉ‡∏ô Sidebar ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏î‡∏≥‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ */
    [data-testid="stSidebar"] .stMarkdown p, 
    [data-testid="stSidebar"] span, 
    [data-testid="stSidebar"] label {
        color: #000000 !important;
        font-weight: 500;
    }

    /* ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Expander */
    .st-emotion-cache-p5mtransition {
        background-color: #FFFFFF !important;
        border-radius: 12px !important;
    }

    /* ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î */
    .stButton>button {
        background-color: #00594C !important;
        color: white !important;
        border-radius: 8px;
        width: 100%;
        border: none;
        font-weight: bold;
    }
    
    /* Chat UI */
    h2 { color: #00594C !important; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- 3. ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ API ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô Settings > Secrets")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    selected = next((m for m in available_models if "1.5-flash" in m), available_models[0])
    return genai.GenerativeModel(model_name=selected)

model = load_model()

# --- 4. ‡∏™‡πà‡∏ß‡∏ô Sidebar: Dashboard & Logo ---
with st.sidebar:
    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏•‡πÇ‡∏Å‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
    if os.path.exists("logo_ku.png"):
        st.image("logo_ku.png", use_container_width=True)
    else:
        st.write("üö© [‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå logo_ku.png]")

    st.markdown('<p class="sidebar-header">üéì ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ Student Dashboard</p>', unsafe_allow_html=True)

    # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß
    with st.expander("üìÇ ‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ö‡∏ö‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏î‡πà‡∏ß‡∏ô (‡∏Ñ‡∏•‡∏¥‡∏Å)", expanded=True):
        st.markdown("---")
        
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà 1
        st.markdown("**üìù ‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô (Registrar-2)**")
        st.link_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î", "https://registrar.ku.ac.th/wp-content/uploads/2024/11/Request-for-Registration.pdf")
        
        st.markdown("---")
        
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà 2
        st.markdown("**üìë ‡∏Ñ‡∏≥‡∏£‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (Registrar-1)**")
        st.link_button("üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î", "https://registrar.ku.ac.th/wp-content/uploads/2023/11/General-Request.pdf")
        
        st.markdown("---")
        
        # ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà 3
        st.markdown("**üíª ‡πÄ‡∏û‡∏¥‡πà‡∏°-‡∏ñ‡∏≠‡∏ô (KU3) ‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå**")
        st.link_button("üåê ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå", "https://reg2.src.ku.ac.th/download.html")

    st.markdown("---")
    st.caption("üíö ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏ô‡∏¥‡∏™‡∏¥‡∏ï‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏™‡∏¥‡∏ï ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.")

# --- 5. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏ô‡πâ‡∏≤ Chat ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡πÇ‡∏´‡∏•‡∏î Knowledge Base
if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

st.markdown("## üêØ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏π‡πà‡∏Ñ‡∏¥‡∏î ‡∏ô‡∏¥‡∏™‡∏¥‡∏ï ‡∏°‡∏Å.‡∏®‡∏£‡∏ä.")

for message in st.session_state.messages:
    avatar = "üßë‚Äçüéì" if message["role"] == "user" else "üêØ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ñ‡∏≤‡∏°‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢..."):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="üêØ"):
        placeholder = st.empty()
        placeholder.markdown("*(‡∏û‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ...)*")
        
        history = [{"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]} 
                   for m in st.session_state.messages[-6:-1]]
        
        try:
            chat_session = model.start_chat(history=history)
            full_context = f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà ‡∏°‡∏Å.‡∏®‡∏£‡∏ä. ‡∏ï‡∏≠‡∏ö‡∏ô‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\n{knowledge_base}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
            
            response = chat_session.send_message(full_context, stream=True)
            full_response = ""
            for chunk in response:
                full_response += chunk.text
                placeholder.markdown(full_response + "‚ñå")
            
            placeholder.markdown(full_response)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            st.rerun()
        except Exception as e:
            st.error(f"Error: {e}")
