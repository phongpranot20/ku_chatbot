import streamlit as st
import google.generativeai as genai
import os
import uuid

st.set_page_config(page_title="KU Sriracha Bot", page_icon="üê¢", layout="wide")

# --- CSS ‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏° ---
st.markdown("""
<style>
    .stApp { background-color: #FFFFFF !important; color: black !important; }
    [data-testid="stSidebar"] { background-color: #f2f9f6 !important; }
    h1, h2, h3, p, span, div { color: #00594C; }
    [data-testid="stChatMessage"] { background-color: #f0f2f6; border-radius: 10px; }
    .stMarkdown p { color: #333333 !important; }
</style>
""", unsafe_allow_html=True)

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API ---
api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        return genai.GenerativeModel(model_name="gemini-1.5-flash")
    except: return None

model = load_model()

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Session State (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà) ---
if "chat_history_dict" not in st.session_state:
    st.session_state.chat_history_dict = {}

if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà
def start_new_chat():
    new_id = str(uuid.uuid4())
    st.session_state.chat_history_dict[new_id] = {"title": "‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà", "messages": []}
    st.session_state.current_chat_id = new_id
    return new_id

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÅ‡∏ä‡∏ó‡πÄ‡∏•‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠ ID ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
if not st.session_state.chat_history_dict or st.session_state.current_chat_id not in st.session_state.chat_history_dict:
    start_new_chat()

# --- Sidebar ---
with st.sidebar:
    st.title("KU Sriracha Bot")
    
    if st.button("‚ûï ‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà", use_container_width=True):
        start_new_chat()
        st.rerun()
    
    st.divider()
    st.subheader("‡πÅ‡∏ä‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÅ‡∏ä‡∏ó
    for chat_id in reversed(list(st.session_state.chat_history_dict.keys())):
        chat_data = st.session_state.chat_history_dict[chat_id]
        # ‡πÑ‡∏Æ‡πÑ‡∏•‡∏ó‡πå‡πÅ‡∏ä‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡∏π‡πà
        is_current = (chat_id == st.session_state.current_chat_id)
        if st.button(chat_data["title"], key=chat_id, use_container_width=True, type="primary" if is_current else "secondary"):
            st.session_state.current_chat_id = chat_id
            st.rerun()

# --- ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å (‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ä‡∏ó‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á) ---
# ‡πÉ‡∏ä‡πâ .get() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError
current_chat = st.session_state.chat_history_dict.get(st.session_state.current_chat_id)

if current_chat:
    st.title(current_chat["title"])

    # ‡πÇ‡∏´‡∏•‡∏î Knowledge Base
    if os.path.exists("ku_data.txt"):
        with open("ku_data.txt", "r", encoding="utf-8") as f:
            knowledge_base = f.read()
    else:
        knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    for message in current_chat["messages"]:
        with st.chat_message(message["role"], avatar="üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"):
            st.markdown(message["content"])

    # ‡∏£‡∏±‡∏ö Input
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡πà‡∏á User
        current_chat["messages"].append({"role": "user", "content": prompt})
        
        # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ä‡∏ó‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏£‡∏Å
        if current_chat["title"] == "‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà":
            current_chat["title"] = prompt[:25] + "..." if len(prompt) > 25 else prompt
            st.rerun() # Rerun ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏ô Sidebar ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

        with st.chat_message("user", avatar="üßë‚Äçüéì"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="ü¶ñ"):
            placeholder = st.empty()
            instruction = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏†‡∏≤‡∏û"
            history_text = "\n".join([f"{m['role']}: {m['content']}" for m in current_chat["messages"][-5:]])
            full_prompt = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {knowledge_base}\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥:\n{history_text}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
            
            try:
                response = model.generate_content(full_prompt, stream=True)
                full_response = ""
                for chunk in response:
                    full_response += chunk.text
                    placeholder.markdown(full_response + "‚ñå")
                
                placeholder.markdown(full_response)
                current_chat["messages"].append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}")
