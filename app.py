import streamlit as st
import google.generativeai as genai
import uuid

# --- 1. CSS ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÅ‡∏ñ‡∏ö‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô + New Chat ‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß) ---
st.set_page_config(page_title="AI TEST", layout="wide")

st.markdown("""
<style>
    [data-testid="stSidebar"] { background-color: #ffffff !important; border-right: 1px solid #eee; }
    
    div.stButton > button {
        width: 100% !important; border: none !important;
        background-color: #ffffff !important; padding: 15px 10px !important;
        text-align: left !important; border-radius: 0px !important;
        border-bottom: 1px solid #f0f0f0 !important; color: #444 !important;
        display: block !important;
    }

    /* ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Ç‡∏µ‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡πâ‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (Active) */
    div[data-testid="stSidebar"] .stButton button[kind="primary"] {
        background-color: #f8f9fa !important; 
        border-left: 6px solid #007bff !important; 
        color: #007bff !important;
        font-weight: 600 !important;
        box-shadow: none !important;
    }

    /* ‡∏õ‡∏∏‡πà‡∏° New Chat: ‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡∏≠‡∏ö‡∏ö‡∏≤‡∏á */
    .stSidebar [data-testid="stVerticalBlock"] > div:nth-child(2) button {
        background-color: #ffffff !important; color: #333 !important;
        border-radius: 8px !important; text-align: center !important;
        border: 1px solid #ddd !important; margin-bottom: 20px !important;
        border-left: none !important;
    }
</style>
""", unsafe_allow_html=True)

st.title("AI TEST")

# --- 2. Setup Model (‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Error ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏Ç‡∏≤‡∏ß) ---
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

@st.cache_resource
def load_working_model():
    try:
        # ‡πÉ‡∏ä‡πâ‡∏£‡∏∏‡πà‡∏ô gemini-1.5-flash ‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        return genai.GenerativeModel('gemini-1.5-flash')
    except:
        return None

model = load_working_model()

# --- 3. Initialization (‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß: ‡∏£‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏≤‡∏¢‡∏ó‡∏±‡∏ô‡∏ó‡∏µ) ---
if "chat_sessions" not in st.session_state:
    st.session_state.chat_sessions = {}
if "current_chat_id" not in st.session_state:
    st.session_state.current_chat_id = None

if st.session_state.current_chat_id is None:
    new_id = str(uuid.uuid4())
    st.session_state.chat_sessions[new_id] = {"title": "New Chat", "messages": []}
    st.session_state.current_chat_id = new_id

current_id = st.session_state.current_chat_id
current_chat = st.session_state.chat_sessions[current_id]

# --- 4. Sidebar ---
with st.sidebar:
    st.header("‡πÄ‡∏°‡∏ô‡∏π‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°")
    if st.button("New Chat", use_container_width=True):
        if len(current_chat["messages"]) > 0:
            new_id = str(uuid.uuid4())
            st.session_state.chat_sessions[new_id] = {"title": "New Chat", "messages": []}
            st.session_state.current_chat_id = new_id
            st.rerun()
    
    st.write("---")
    st.subheader("‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢")
    for chat_id, chat_data in reversed(list(st.session_state.chat_sessions.items())):
        if len(chat_data["messages"]) > 0:
            is_active = (chat_id == current_id)
            if st.button(
                chat_data["title"], 
                key=chat_id, 
                use_container_width=True,
                type="primary" if is_active else "secondary"
            ):
                st.session_state.current_chat_id = chat_id
                st.rerun()

# --- 5. ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• (üßë‚Äçüéì ‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï / ü¶ñ ‡πÑ‡∏î‡πÇ‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå) ---
for m in current_chat["messages"]:
    avatar = "üßë‚Äçüéì" if m["role"] == "user" else "ü¶ñ"
    with st.chat_message(m["role"], avatar=avatar):
        st.markdown(m["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
    with st.chat_message("user", avatar="üßë‚Äçüéì"):
        st.markdown(prompt)
    current_chat["messages"].append({"role": "user", "content": prompt})
    
    if len(current_chat["messages"]) == 1:
        current_chat["title"] = prompt[:25]

    with st.chat_message("assistant", avatar="ü¶ñ"):
        placeholder = st.empty()
        # ‡∏™‡πà‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏Ñ‡πà 3 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î Token/Quota
        history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in current_chat["messages"][-3:]])
        try:
            if model:
                response = model.generate_content(f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏û‡∏µ‡πà‡∏ô‡∏ô‡∏ó‡∏£‡∏µ\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥:\n{history}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}")
                placeholder.markdown(response.text)
                current_chat["messages"].append({"role": "assistant", "content": response.text})
                st.rerun()
        except Exception as e:
            # ‡∏´‡∏≤‡∏Å‡∏ï‡∏¥‡∏î Error 429 (Quota) ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏Ñ‡πâ‡∏≤‡∏á
            st.error("‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤‡πÄ‡∏ï‡πá‡∏°‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠‡∏™‡∏±‡∏Å 15 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö")
