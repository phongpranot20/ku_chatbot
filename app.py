import streamlit as st
import google.generativeai as genai
import os

# 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
st.set_page_config(
    page_title="KU Sriracha Bot",
    page_icon="üê¢",
    layout="wide"
)

# üé® ‡∏ò‡∏µ‡∏°‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß KU + ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≤‡∏ß
st.markdown("""
<style>
    .stApp { background-color: #FFFFFF !important; color: black !important; }
    [data-testid="stSidebar"] { background-color: #f2f9f6 !important; }
    h1, h2, h3, p, span, div { color: #00594C; }
    [data-testid="stChatMessage"] { background-color: #f0f2f6; border-radius: 10px; }
    .stMarkdown p { color: #333333 !important; }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------------------
# 2. ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (API Key) - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
# -------------------------------------------------------------
# ‡∏î‡∏∂‡∏á API Key ‡∏à‡∏≤‡∏Å Secrets ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏à‡∏£‡∏¥‡∏á‡∏•‡∏á‡πÉ‡∏ô‡∏ô‡∏µ‡πâ)
if "GEMINI_API_KEY" in st.secrets:
    api_key = st.secrets["GEMINI_API_KEY"]
else:
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á (Local) ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå .streamlit/secrets.toml
    api_key = os.environ.get("GEMINI_API_KEY")

if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Secrets (GEMINI_API_KEY)")
    st.stop()

genai.configure(api_key=api_key)

# ‚öôÔ∏è ‡∏£‡∏∞‡∏ö‡∏ö Auto-Switch ‡πÇ‡∏°‡πÄ‡∏î‡∏•
def get_working_model():
    model_list = ['gemini-1.5-flash', 'gemini-1.5-pro']
    for model_name in model_list:
        try:
            model = genai.GenerativeModel(model_name)
            return model
        except:
            continue
    return genai.GenerativeModel('gemini-1.5-flash')

model = get_working_model()

# -------------------------------------------------------------
# 3. Sidebar
# -------------------------------------------------------------
with st.sidebar:
    st.markdown('<h3 style="text-align: center;">‡πÄ‡∏°‡∏ô‡∏π‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á</h3>', unsafe_allow_html=True)
    if st.button("üóëÔ∏è ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó", use_container_width=True):
        st.session_state.messages = []
        st.rerun()

# -------------------------------------------------------------
# 4. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏ä‡∏ó
# -------------------------------------------------------------
st.title("üê¢ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ (AI Assistant)")

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
if os.path.exists("ku_data.txt"):
    with open("ku_data.txt", "r", encoding="utf-8") as f:
        knowledge_base = f.read()
else:
    knowledge_base = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤"

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"):
        st.markdown(message["content"])

if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà..."):
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ñ‡∏∏‡∏°‡∏™‡∏ï‡∏¥ AI ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏Å‡πà‡∏á‡πÜ
        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' AI ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏Ç‡∏≠‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ (KU SRC) "
            "‡∏Å‡∏é‡πÄ‡∏´‡∏•‡πá‡∏Å: 1. ‡∏ï‡∏≠‡∏ö‡∏™‡∏∏‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á 2. ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏∂‡∏Å ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏•‡∏¥‡πâ‡∏á‡∏Ñ‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏™‡∏°‡∏≠ "
            "3. ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏ö‡∏ö‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÉ‡∏Å‡∏•‡πâ‡πÜ ‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á) "
            "4. ‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î"
        )
        
        full_prompt = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á: {knowledge_base}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {prompt}"
        
        try:
            response = model.generate_content(full_prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {e}")
