import streamlit as st
import google.generativeai as genai
import os

st.set_page_config(page_title="KU Sriracha Bot", page_icon="üê¢", layout="wide")

st.markdown("""
<style>
    .stApp { background-color: #FFFFFF !important; color: black !important; }
    [data-testid="stSidebar"] { background-color: #f2f9f6 !important; }
    h1, h2, h3, p, span, div { color: #00594C; }
    [data-testid="stChatMessage"] { background-color: #f0f2f6; border-radius: 10px; }
    .stMarkdown p { color: #333333 !important; }

    /* Animation ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏∏‡∏î Loading */
    .loading-dots {
        font-size: 30px;
        font-weight: bold;
        display: inline-block;
    }
    .loading-dots:after {
        content: '.';
        animation: dots 1.5s steps(5, end) infinite;
    }
    @keyframes dots {
        0%, 20% { content: '.'; }
        40% { content: '..'; }
        60% { content: '...'; }
        80%, 100% { content: ''; }
    }
    
    /* ‡∏ï‡∏Å‡πÅ‡∏ï‡πà‡∏á‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏≤‡∏á‡∏•‡∏±‡∏î */
    .stButton button {
        width: 100%;
        border-radius: 20px;
        border: 1px solid #00594C;
        color: #00594C;
        background-color: transparent;
        transition: 0.3s;
    }
    .stButton button:hover {
        background-color: #00594C;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

api_key = st.secrets.get("GEMINI_API_KEY")
if not api_key:
    st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ Settings > Secrets")
    st.stop()

genai.configure(api_key=api_key)

@st.cache_resource
def load_model():
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                if "flash" in m.name.lower():
                    return genai.GenerativeModel(model_name=m.name)
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                return genai.GenerativeModel(model_name=m.name)
    except Exception as e:
        st.error(f"‚ùå ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ: {e}")
    return None

model = load_model()

if not model:
    st.stop()

st.title("ü¶ñ ‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ AI (KU SRC)")

# --- ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏∏‡πà‡∏°‡∏ó‡∏≤‡∏á‡∏•‡∏±‡∏î (Quick Reply) ---
st.write("üí° ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:")
col1, col2, col3, col4 = st.columns(4)
btn_prompt = None

with col1:
    if st.button("üìç ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"):
        btn_prompt = "‡∏Ç‡∏≠‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ï‡∏∂‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÜ ‡πÉ‡∏ô ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ ‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö"
with col2:
    if st.button("üçΩÔ∏è ‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏î‡πá‡∏î"):
        btn_prompt = "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡πâ‡∏≤‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡∏≠‡∏£‡πà‡∏≠‡∏¢‡πÜ ‡∏£‡∏≠‡∏ö‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏û‡∏µ‡πà"
with col3:
    if st.button("üìÑ ‡∏á‡∏≤‡∏ô‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"):
        btn_prompt = "‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Ç‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ù‡πà‡∏≤‡∏¢‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"
with col4:
    if st.button("üöå ‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•"):
        btn_prompt = "‡∏£‡∏ñ‡∏ï‡∏∞‡πÑ‡∏•‡πÉ‡∏ô‡∏°‡∏≠‡∏ß‡∏¥‡πà‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö"

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar="üßë‚Äçüéì" if message["role"] == "user" else "ü¶ñ"):
        st.markdown(message["content"])

# ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡πÅ‡∏ä‡∏ó
chat_input = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
prompt = chat_input if chat_input else btn_prompt

if prompt:
    st.chat_message("user", avatar="üßë‚Äçüéì").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant", avatar="ü¶ñ"):
        status_placeholder = st.empty()
        status_placeholder.markdown('<div class="loading-dots"></div>', unsafe_allow_html=True)
        
        instruction = (
            "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ '‡∏ô‡πâ‡∏≠‡∏á‡∏ô‡∏ô‡∏ó‡∏£‡∏µ' AI ‡∏£‡∏∏‡πà‡∏ô‡∏û‡∏µ‡πà‡∏Ç‡∏≠‡∏á ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤ (KU SRC) "
            "‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏≠‡∏á ‡πÅ‡∏ó‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á‡∏ß‡πà‡∏≤ '‡∏û‡∏µ‡πà' ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ß‡πà‡∏≤ '‡∏ô‡πâ‡∏≠‡∏á' "
            "‡∏à‡∏á‡∏à‡∏≥‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏™‡∏°‡∏≠ "
            "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡∏´‡∏≤‡∏Å‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡∏∂‡∏Å ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÅ‡∏ú‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏°‡∏≠"
        )
        
        history_text = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-10:]])
        full_prompt = f"{instruction}\n\n‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {knowledge_base if 'knowledge_base' in locals() else '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏°‡∏Å. ‡∏®‡∏£‡∏µ‡∏£‡∏≤‡∏ä‡∏≤'}\n\n‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∏‡∏¢:\n{history_text}\n\n‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: {prompt}"
        
        try:
            response = model.generate_content(full_prompt)
            status_placeholder.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            status_placeholder.empty()
            st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
